# HEKTOR Perceptual Quantization (PQ) Studio - Comprehensive Design
## Design Specification v2.0

**Document Version:** 2.0.0  
**Date:** January 2026  
**Status:** Production Design  
**Authors:** HEKTOR Development Team  
**Size Target:** 18-20KB

---

## Executive Summary

The **HEKTOR Perceptual Quantization Studio** represents the world's first HDR-aware quantization system for vector databases. Unlike traditional quantization methods that treat all dimensions equally, our PQ Studio integrates perceptual quality metrics from HDR imaging to intelligently compress high-dimensional vectors while preserving semantic meaning and visual fidelity.

### Key Differentiators

- **Industry-First HDR-Aware Quantization**: Applies PU21 (Perceptually Uniform) encoding to vector spaces
- **Real-Time Visual Feedback**: See quantization effects instantly with interactive before/after comparisons
- **Multi-Method Support**: PQ (Product Quantization), SQ (Scalar Quantization), OPQ (Optimized Product Quantization)
- **Perceptual Quality Metrics**: PSNR, SSIM, HDR-VDP, custom vector similarity scores
- **Codebook Training Workbench**: Visual interface for training, editing, and optimizing quantization codebooks
- **3D Integration**: Visualize quantization error in vector space with color-coded heatmaps
- **Batch Processing Pipeline**: Process millions of vectors with progress tracking and quality reports

### Business Value

- **10-32x compression** with minimal quality loss (4-8% recall degradation)
- **Sub-millisecond search** on billion-scale datasets
- **80% memory savings** for embedding storage
- **Production-ready** tooling for ML engineers and data scientists

---

## Table of Contents

1. [Architecture Overview](#architecture-overview)
2. [UI/UX Design](#uiux-design)
3. [Core Components](#core-components)
4. [Quantization Workflows](#quantization-workflows)
5. [Visual Quality Tools](#visual-quality-tools)
6. [Codebook Management](#codebook-management)
7. [Performance Profiling](#performance-profiling)
8. [Integration Points](#integration-points)
9. [Technology Stack](#technology-stack)
10. [Implementation Phases](#implementation-phases)
11. [Testing Strategy](#testing-strategy)

---

## 1. Architecture Overview

### 1.1 System Architecture Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              PQ Studio Frontend (React + Three.js)              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Comparison     â”‚ Metrics      â”‚ Codebook     â”‚ 3D              â”‚
â”‚ View           â”‚ Dashboard    â”‚ Manager      â”‚ Visualizer      â”‚
â”‚ (4-panel)      â”‚ (Real-time)  â”‚ (Training)   â”‚ (Error Heat)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚              â”‚              â”‚                â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        Electron IPC Bridge (contextBridge API)                  â”‚
â”‚   â€¢ quantization/train, encode, decode                          â”‚
â”‚   â€¢ metrics/compute, compare                                    â”‚
â”‚   â€¢ codebook/load, save, validate                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚              â”‚              â”‚                â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      N-API Bindings (C++ â†” TypeScript)                         â”‚
â”‚  â€¢ NAPI::Object serialization/deserialization                  â”‚
â”‚  â€¢ Async worker threads for heavy computation                  â”‚
â”‚  â€¢ Memory-safe data marshalling                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚              â”‚              â”‚                â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          HEKTOR C++23 Core Library (src/quantization/)         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ ProductQuantizer: k-means clustering on subvectors           â”‚
â”‚ â€¢ ScalarQuantizer: Per-dimension int8/int16 quantization       â”‚
â”‚ â€¢ AdaptiveQuantizer: HDR-aware per-dimension scaling           â”‚
â”‚ â€¢ PerceptualCurves: PU21 encoding (ITU-R BT.2100)             â”‚
â”‚ â€¢ StructuredQuantizer: OPQ rotation optimization               â”‚
â”‚ â€¢ CodebookManager: Training, validation, serialization         â”‚
â”‚ â€¢ QualityMetrics: PSNR, SSIM, MSE, recall@K                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.2 Data Flow Architecture

**Training Workflow:**
```
Raw Vector Set (NÃ—D)
        â†“
  [Sampling Stage] â†’ Select representative 10K vectors
        â†“
  [Normalization] â†’ Min-max or standard scaling
        â†“
  [Clustering] â†’ k-means on subvectors (M subgroups)
        â†“
  [Codebook Generation] â†’ MÃ—K centroid matrix
        â†“
  [Perceptual Optimization] â†’ Apply PU21 to centroids
        â†“
  [Validation] â†’ Test on holdout set
        â†“
  [Export] â†’ Save codebook + metadata (JSON/Binary)
```

**Encoding Workflow:**
```
Input Vector (D dimensions)
        â†“
  [Perceptual Transform] â†’ Optional PU21 pre-processing
        â†“
  [Quantization Method] â†’ PQ/SQ/OPQ assigns codes
        â†“
  [Code Generation] â†’ M codes (8-bit each for PQ)
        â†“
  [Validation Check] â†’ Verify quality thresholds
        â†“
  [Storage] â†’ Compressed vector + index entry
```

**Visual Comparison:**
```
Original + Quantized vectors
        â†“
  [Batch Decode] â†’ Reconstruct from codes
        â†“
  [Metric Computation] â†’ PSNR, SSIM, MSE, recall
        â†“
  [Difference Calculation] â†’ Element-wise error
        â†“
  [3D Rendering] â†’ Positions + error heatmap
        â†“
  [Interactive Dashboard] â†’ Update charts/visualizations
```

---

## 2. UI/UX Design

### 2.1 Main Interface Layout (4-Panel Workspace)

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘ HEKTOR PQ Studio    [â—‹ â—‹ â—‹]  [Theme] [Settings] [Help]           â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â•‘
â•‘ â”‚ğŸ“Š Dashboard  â”‚ â”‚ğŸ¯ Quantize   â”‚ â”‚ğŸ“– Codebooks              â”‚   â•‘
â•‘ â”‚(Active)      â”‚ â”‚              â”‚ â”‚                          â”‚   â•‘
â•‘ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ LEFT PANEL (40%)          â”‚  RIGHT PANEL (60%)                    â•‘
â•‘ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â•‘
â•‘ â”‚  ORIGINAL VECTORS     â”‚ â”‚ â”‚  QUANTIZED VECTORS               â”‚ â•‘
â•‘ â”‚  (3D View)            â”‚ â”‚ â”‚  (3D View)                       â”‚ â•‘
â•‘ â”‚  [Rotation enabled]   â”‚ â”‚ â”‚  [Error heatmap overlay]         â”‚ â•‘
â•‘ â”‚                       â”‚ â”‚ â”‚                                  â”‚ â•‘
â•‘ â”‚ â€¢ 10,000 points       â”‚ â”‚ â”‚ â€¢ 10,000 points                  â”‚ â•‘
â•‘ â”‚ â€¢ Float32 (400KB)     â”‚ â”‚ â”‚ â€¢ Int8 (100KB)                   â”‚ â•‘
â•‘ â”‚ â€¢ Blue coloring       â”‚ â”‚ â”‚ â€¢ Red-Green heatmap              â”‚ â•‘
â•‘ â”‚                       â”‚ â”‚ â”‚                                  â”‚ â•‘
â•‘ â”‚ [Sync Camera] [Layer] â”‚ â”‚ â”‚ [Error Threshold â–“â–“â–“â–‘] Export   â”‚ â•‘
â•‘ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ CONTROL PANEL (40%)       â”‚  METRICS DASHBOARD (60%)              â•‘
â•‘ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â•‘
â•‘ â”‚Method: [PQ        â–¼]  â”‚ â”‚ âš¡ PERFORMANCE METRICS             â”‚ â•‘
â•‘ â”‚Subvectors: [8     â–¼]  â”‚ â”‚ â€¢ Compression: 4.2x               â”‚ â•‘
â•‘ â”‚Codebook: [256     â–¼]  â”‚ â”‚ â€¢ Memory: 400KB â†’ 95KB            â”‚ â•‘
â•‘ â”‚                       â”‚ â”‚ â€¢ Search Speedup: +215%           â”‚ â•‘
â•‘ â”‚â˜‘ Perceptual (PU21)    â”‚ â”‚                                    â”‚ â•‘
â•‘ â”‚â˜‘ Adaptive Scaling     â”‚ â”‚ ğŸ“Š QUALITY METRICS                â”‚ â•‘
â•‘ â”‚â˜‘ Validate on Encode   â”‚ â”‚ â€¢ PSNR: 42.3 dB      â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘    â”‚ â•‘
â•‘ â”‚                       â”‚ â”‚ â€¢ SSIM: 0.9401       â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘   â”‚ â•‘
â•‘ â”‚ [ğŸ¯ Quantize Now]     â”‚ â”‚ â€¢ MSE: 0.00122       â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘   â”‚ â•‘
â•‘ â”‚ [ğŸ“Š Batch Process]    â”‚ â”‚ â€¢ Recall@10: 96.2%   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘   â”‚ â•‘
â•‘ â”‚ [ğŸ’¾ Export Results]   â”‚ â”‚                                    â”‚ â•‘
â•‘ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

### 2.2 Key UI Screens

**Dashboard View:**
- Active quantization jobs (progress bars with ETA)
- Codebook library (grid with thumbnails, compression ratio, date)
- Recent comparisons (history with clickable entries)
- System metrics (GPU memory, cache hit rate, CPU usage)
- Quick action buttons (Train New, Load, Export)

**Quantization Control Panel:**
- Method selector (PQ/SQ/OPQ)
- Hyperparameter controls (subvector count, codebook size)
- Optimization toggles (Perceptual mode, Adaptive scaling)
- Validation options (Threshold setup, Holdout size)
- Execute buttons with clear labeling

**3D Comparison Visualization:**
- Synchronized camera controls (zoom, rotate, pan)
- Side-by-side or overlay modes
- Error heatmap with adjustable color scale
- Dimension selector (project 3D from N-D)
- Hover tooltips showing vector IDs and metrics

**Codebook Manager:**
- Training interface with live progress
- Codebook browser with metadata
- Validation results dashboard
- Edit centroids directly (advanced mode)
- Export options (JSON, Binary, ONNX)

### 2.3 Comparison View Modes

**Mode 1: Side-by-Side**
- Original (left) vs Quantized (right) in 3D
- Synchronized pan/zoom/rotate
- Hover shows: vector_id, original_values[0:3], quantized_values[0:3], error_magnitude

**Mode 2: Overlay**
- Original (blue) and Quantized (orange) in same 3D space
- Toggle layer visibility
- Error vectors shown as red arrows
- Density heatmap option

**Mode 3: Error Heatmap**
- Color intensity = error magnitude
- Red (high error) â†” Green (low error)
- Adjustable threshold sliders
- Export as high-resolution PNG

**Mode 4: Temporal Animation**
- Play quantization process step-by-step
- Watch codebook clustering iterations
- Adjustable playback speed (0.5x - 4x)
- Pause to inspect intermediate states

---

## 3. Core Components

### 3.1 ProductQuantizer Implementation

**Location:** `src/quantization/ProductQuantizer.cpp`

**Algorithm:**
1. Partition D-dimensional vector into M subvectors (M=8 typical)
2. For each subvector, apply k-means clustering with K centroids (K=256)
3. Encode each subvector as index into its codebook (8 bits)
4. Full vector encoded as MÃ—8 bits = M bytes

**Key Methods:**
```cpp
class ProductQuantizer {
  // Training: clusters subvectors
  void train(const float* vectors, size_t n_vectors, size_t dim, 
             size_t m_subvectors, size_t k_centroids);
  
  // Encoding: assign indices
  void encode(const float* vector, uint8_t* codes);
  
  // Decoding: reconstruct from codes
  void decode(const uint8_t* codes, float* vector);
  
  // Batch operations with SIMD
  void encode_batch(const float* vectors, size_t n, uint8_t* codes);
  void decode_batch(const uint8_t* codes, size_t n, float* vectors);
  
  // Validation
  float compute_error(const float* original, const uint8_t* codes);
};
```

**Performance Characteristics:**
- Training: O(nÃ—dÃ—kÃ—iterations) â‰ˆ 2-5 sec for 100K 768D vectors
- Encoding: ~500 ns per vector (SIMD optimized)
- Decoding: ~300 ns per vector
- Memory: KÃ—MÃ—DÃ—4 bytes â‰ˆ 2-8 MB for 256K codebook

### 3.2 ScalarQuantizer Implementation

**Location:** `src/quantization/ScalarQuantizer.cpp`

**Algorithm:**
1. For each dimension, compute min/max values
2. Map float range [min, max] to int8 or int16
3. Store min/max per dimension for reconstruction

**Key Methods:**
```cpp
class ScalarQuantizer {
  // Per-dimension quantization
  void train(const float* vectors, size_t n_vectors, size_t dim);
  
  void encode(const float* vector, int8_t* codes);
  void decode(const int8_t* codes, float* vector);
  
  // Batch encoding with vectorization
  void encode_batch(const float* vectors, size_t n, int8_t* codes);
  void decode_batch(const int8_t* codes, size_t n, float* vectors);
  
  // Inspect scaling parameters
  const std::vector<float>& get_mins() const;
  const std::vector<float>& get_maxs() const;
};
```

**Performance:**
- Encoding: ~100 ns per vector (single pass)
- Decoding: ~150 ns per vector
- Memory savings: 32x (from float32 to int8)
- Compression ratio: 4:1 exactly

### 3.3 AdaptiveQuantizer (HDR-Aware)

**Location:** `src/quantization/AdaptiveQuantizer.cpp`

**Key Innovation:** Per-dimension bit allocation based on perceptual importance

**Algorithm:**
1. Apply PU21 transform to compute perceptual distances
2. Compute variance/entropy for each dimension
3. Allocate bits: important dimensions get more precision
4. Use variable-length codes (adaptive entropy encoding)

**Key Methods:**
```cpp
class AdaptiveQuantizer {
  // PU21-aware training
  void train(const float* vectors, size_t n_vectors, size_t dim);
  
  // Compute per-dimension bit allocations
  std::vector<uint8_t> compute_bit_allocation();
  
  // Adaptive encoding with variable-length codes
  void encode(const float* vector, BitWriter& writer);
  void decode(BitReader& reader, float* vector);
  
  // Get perceptual importance scores
  const std::vector<float>& get_importance_scores() const;
};
```

**PU21 Implementation:**
- Maps linear brightness [0, 1] to perceptually uniform space
- Formula: `L'_D65 = 10000 * pow((V + delta) / (1 + delta), 2)`
- Applied to normalized vector components
- Preserves semantic relationships while respecting human perception

### 3.4 StructuredQuantizer (OPQ)

**Location:** `src/quantization/StructuredQuantizer.cpp`

**Algorithm:** Optimized Product Quantization with rotation optimization
1. Train initial ProductQuantizer
2. Learn orthogonal rotation matrix R via alternating optimization
3. Apply rotation to input vectors before encoding
4. Reduces quantization error by 2-3x

**Key Methods:**
```cpp
class StructuredQuantizer {
  void train(const float* vectors, size_t n_vectors, size_t dim);
  
  // Rotation matrix
  const float* get_rotation_matrix() const; // dim x dim
  
  void encode(const float* vector, uint8_t* codes);
  void decode(const uint8_t* codes, float* vector);
};
```

---

## 4. Quantization Workflows

### 4.1 Product Quantization Workflow

**Training Workflow:**

```
Step 1: Load Dataset
â”œâ”€ Accept: CSV, Parquet, HDF5, Raw binary
â”œâ”€ Memory map for large files (>1GB)
â””â”€ Detect dimensionality automatically

Step 2: Configuration
â”œâ”€ Select M (subvectors): 4, 8, 16 options
â”œâ”€ Select K (codebook size): 256, 512, 1024 options
â”œâ”€ Optional: Sampling ratio (default 10K or 10%)
â””â”€ Perceptual mode toggle

Step 3: Preprocessing
â”œâ”€ Normalization (optional L2 norm)
â”œâ”€ Dimension reduction (optional PCA to 256D)
â”œâ”€ Outlier detection and handling
â””â”€ Compute statistics for UI display

Step 4: Clustering
â”œâ”€ Initialize subvector codebooks with k-means++
â”œâ”€ Iterate: assign vectors â†’ update centroids
â”œâ”€ Monitor convergence (max 20 iterations)
â”œâ”€ Live progress: "Clustering subvector 3/8... Iteration 5/20"
â””â”€ Compute loss curve for visualization

Step 5: Perceptual Optimization (if enabled)
â”œâ”€ Transform codebook centroids with PU21
â”œâ”€ Recompute distances in perceptual space
â”œâ”€ Fine-tune centroids (2-3 iterations)
â””â”€ Measure improvement: "Perceptual loss reduced by 7%"

Step 6: Validation
â”œâ”€ Encode holdout set (default 1000 vectors)
â”œâ”€ Compute PSNR, SSIM, MSE, recall@K
â”œâ”€ Generate quality report
â””â”€ Display pass/fail on configured thresholds

Step 7: Export
â”œâ”€ Serialize codebook (metadata + centroids)
â”œâ”€ Save training config (hyperparameters)
â”œâ”€ Generate certificate of quality
â””â”€ Create thumbnail for library
```

### 4.2 Scalar Quantization Workflow

**Simpler flow for int8 conversion:**

```
Step 1: Load vectors â†’ Step 2: Compute min/max per dimension
         â†“
Step 3: Linear scaling to [0, 255] or [-128, 127]
         â†“
Step 4: Encode with int8
         â†“
Step 5: Validate reconstruction error
         â†“
Step 6: Export with min/max lookup tables
```

### 4.3 OPQ Workflow

**Enhanced PQ with rotation optimization:**

```
Step 1-3: Same as PQ (Load, Config, Preprocess)
         â†“
Step 4: Train initial PQ codebooks
         â†“
Step 5: Rotation Learning
        â”œâ”€ Initialize R as identity matrix
        â”œâ”€ Iterate: encode with current R â†’ optimize R â†’ new assignments
        â”œâ”€ Monitor: "Rotation optimization cycle 3/5... MSE reduced by 2.3%"
        â””â”€ Convergence check
         â†“
Step 6: Final codebook adjustment
         â†“
Step 7: Export (includes rotation matrix)
```

---

## 5. Visual Quality Tools

### 5.1 Quality Metrics Implementation

**Location:** `src/quantization/QualityMetrics.cpp`

**Metric 1: PSNR (Peak Signal-to-Noise Ratio)**
```cpp
float compute_psnr(const float* original, const float* reconstructed,
                   size_t n_elements) {
  // MSE = mean((original - reconstructed)^2)
  // PSNR = 10 * log10(MAX_VAL^2 / MSE)
  // Typical values: 30-50 dB (higher is better)
  float mse = compute_mse(original, reconstructed, n_elements);
  return 10.0f * std::log10(1.0f / mse); // assuming normalized [0,1]
}
```

**Metric 2: SSIM (Structural Similarity Index)**
```cpp
float compute_ssim(const float* original, const float* reconstructed,
                   size_t n_elements, size_t window_size = 64) {
  // Measures perceptual similarity considering:
  // - Luminance similarity
  // - Contrast similarity
  // - Structure similarity
  // Range: [-1, 1] (1 = identical)
  
  // Implementation uses sliding windows on vector space
  // Typical values: 0.85-0.99 (higher is better)
}
```

**Metric 3: MSE (Mean Squared Error)**
```cpp
float compute_mse(const float* original, const float* reconstructed,
                  size_t n_elements) {
  float sum = 0.0f;
  for (size_t i = 0; i < n_elements; i++) {
    float diff = original[i] - reconstructed[i];
    sum += diff * diff;
  }
  return sum / n_elements;
}
```

**Metric 4: Recall@K**
```cpp
float compute_recall_at_k(const float* original, const float* quantized,
                         const std::vector<std::vector<int>>& neighbors_orig,
                         const std::vector<std::vector<int>>& neighbors_quant,
                         int k = 10) {
  // Measures ANN quality: % of original k-NN preserved in quantized space
  // Typical values: 92-98% for good quantization
  int matches = 0;
  for (int i = 0; i < k; i++) {
    // Check if neighbors_quant[i] in neighbors_orig[0:k]
  }
  return (float)matches / k;
}
```

### 5.2 Real-Time Metrics Dashboard

**Display Components:**
- Compression ratio (original_size / quantized_size)
- Memory savings (bytes saved, percentage)
- Speed comparison (original vs quantized search time)
- Quality scores (PSNR, SSIM, MSE, Recall@10)
- Confidence indicators (green/yellow/red based on thresholds)

**Update Frequency:** Every 100ms (throttled)

### 5.3 3D Error Visualization

**Implementation:**
```javascript
// Three.js visualization
const geometry = new THREE.BufferGeometry();
geometry.setAttribute('position', original_positions);

// Error as vertex colors
const colors = new Uint8Array(n_vectors * 3);
for (let i = 0; i < n_vectors; i++) {
  const error = compute_error(original[i], quantized[i]);
  const normalized_error = Math.min(error / max_error, 1.0);
  
  // Red-Green heatmap
  colors[i*3] = Math.round(normalized_error * 255);     // Red channel
  colors[i*3+1] = Math.round((1-normalized_error) * 255); // Green channel
  colors[i*3+2] = 0;                                      // Blue channel
}

geometry.setAttribute('color', new THREE.BufferAttribute(colors, 3, true));
const material = new THREE.PointsMaterial({vertexColors: true, size: 0.5});
```

**Features:**
- Adjustable color scale (min/max error thresholds)
- Toggle between error magnitude and component-wise error
- Select specific vector to highlight
- Export visualization as high-res PNG

---

## 6. Codebook Management

### 6.1 Codebook Storage Format

**JSON Format (Human-Readable):**
```json
{
  "metadata": {
    "method": "ProductQuantization",
    "version": "2.0",
    "created": "2026-01-23T10:30:00Z",
    "dim": 768,
    "n_subvectors": 8,
    "codebook_size": 256,
    "dataset_size": 100000,
    "perceptual_mode": true
  },
  "training_stats": {
    "psnr": 42.3,
    "ssim": 0.9401,
    "mse": 0.00122,
    "recall_at_10": 0.962,
    "compression_ratio": 4.2,
    "encoding_time_us": 0.52,
    "decoding_time_us": 0.31
  },
  "codebooks": [
    {
      "subvector_id": 0,
      "start_dim": 0,
      "end_dim": 96,
      "centroids": [
        [0.123, 0.456, ..., 0.789],  // centroid 0
        [0.234, 0.567, ..., 0.890],  // centroid 1
        ...
      ]
    },
    ...
  ]
}
```

**Binary Format (Optimized for Speed):**
```
[Header: 64 bytes]
  - Magic: "HEKT" (4 bytes)
  - Version: 2.0 (4 bytes)
  - Method: int32 (4 bytes)
  - Dim: int32 (4 bytes)
  - M, K: int32 (8 bytes)
  - Flags: (8 bytes, perceptual, adaptive, etc)
  - Training stats: (32 bytes: PSNR, SSIM, MSE, recall)

[Codebook Data]
  - M Ã— K Ã— D Ã— 4 bytes (float32 centroids)
  
[Optional: Rotation Matrix]
  - D Ã— D Ã— 4 bytes (for OPQ)
  
[Optional: Metadata]
  - Variable length string with training info
```

### 6.2 Codebook Library UI

**Browser Interface:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ“– Codebook Library (12 saved)                    [+ New]   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Filter: [All â–¼] Search: [_________]  Sort: [Date â–¼]        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚ â”‚ Codebook â”‚ â”‚ Codebook â”‚ â”‚ Codebook â”‚ â”‚ Codebook â”‚         â”‚
â”‚ â”‚ ImageNet â”‚ â”‚ Text-768 â”‚ â”‚ AugmentD â”‚ â”‚ Medical  â”‚         â”‚
â”‚ â”‚ PQ 8Ã—256 â”‚ â”‚ SQ int8  â”‚ â”‚ OPQ      â”‚ â”‚ Adaptive â”‚         â”‚
â”‚ â”‚ ğŸŸ¢ 4.2x  â”‚ â”‚ ğŸŸ¡ 4.1x  â”‚ â”‚ ğŸŸ¢ 5.1x  â”‚ â”‚ ğŸ”´ 3.2x  â”‚         â”‚
â”‚ â”‚ Jan 23   â”‚ â”‚ Jan 20   â”‚ â”‚ Jan 18   â”‚ â”‚ Jan 15   â”‚         â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚ â”‚ Selected: ImageNet-PQ-8x256                             â”‚â”‚
â”‚ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚â”‚
â”‚ â”‚ â”‚ PSNR: 42.3 dB  â”‚ SSIM: 0.940  â”‚ Recall@10: 96.2% â”‚ â”‚â”‚
â”‚ â”‚ â”‚ Compression: 4.2x  â”‚ Memory: 93.5 KB             â”‚ â”‚â”‚
â”‚ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚â”‚
â”‚ â”‚ [Load] [Duplicate] [Export] [Delete] [Visualize]       â”‚â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 6.3 Codebook Training Interface

**Live Training Monitor:**
- Real-time progress bars (k-means iterations)
- Live loss curves (MSE, perceptual loss)
- Current statistics display
- ETA calculation
- Pause/Resume controls
- Cancel button with confirmation

**Centroids Editor (Advanced Mode):**
- View/edit individual centroids
- Visualize centroid distribution
- Merge similar centroids
- Add/remove centroids manually
- Re-train from checkpoint

---

## 7. Performance Profiling

### 7.1 Profiling Dashboard

**Metrics Tracked:**
```
Encoding Performance:
â”œâ”€ Throughput: vectors/sec (e.g., 2M vectors/sec)
â”œâ”€ Latency: p50/p95/p99 (e.g., 0.5Âµs / 0.7Âµs / 1.2Âµs)
â”œâ”€ Memory bandwidth: GB/sec
â””â”€ Cache hit rate: %

Decoding Performance:
â”œâ”€ Throughput
â”œâ”€ Latency distribution
â”œâ”€ Memory access patterns
â””â”€ Vectorization efficiency

Search Performance:
â”œâ”€ QPS (queries/sec) on quantized vs original
â”œâ”€ Recall degradation curve
â”œâ”€ Memory footprint
â””â”€ L3 cache efficiency
```

### 7.2 Benchmarking Tools

**Built-in Benchmarks:**
```cpp
// Encoding benchmark
std::vector<float> vectors = load_dataset(1M);
auto start = high_resolution_clock::now();
for (auto& v : vectors) {
  encoder.encode(v.data(), codes.data());
}
auto duration = high_resolution_clock::now() - start;
// Report: vectors/sec, latency percentiles, memory bandwidth
```

**Performance Profiles:**
- CPU: Peak throughput with SIMD optimization
- Memory: Bandwidth utilization
- GPU: Optional CUDA kernels for batch operations
- Cache: L1/L2/L3 hit rates

---

## 8. Integration Points

### 8.1 Integration with HEKTOR Core

**Quantization Module Interface:**
```cpp
namespace vdb::quantization {
  class IQuantizer {
    virtual void train(const float* vectors, size_t n, size_t dim) = 0;
    virtual void encode(const float* vector, uint8_t* codes) = 0;
    virtual void decode(const uint8_t* codes, float* vector) = 0;
    virtual size_t encoded_size() const = 0;
  };

  // Factory
  std::unique_ptr<IQuantizer> create_quantizer(QuantizerType type);
}
```

### 8.2 Database Integration

**Storing Quantized Vectors:**
```python
# Python API
from hektor import VectorDB

vdb = VectorDB("mydb")
quantizer = vdb.create_quantizer(method="PQ", subvectors=8)

# Train on subset
quantizer.train(vectors[:100000])

# Encode all vectors
encoded_vectors = quantizer.encode_batch(vectors)

# Store in database
vdb.insert_quantized(ids, encoded_vectors, quantizer)

# Search with quantization
results = vdb.search(query_embedding, k=10, quantized=True)
```

### 8.3 REST API for PQ Studio

**Endpoints:**
```
POST   /api/quantization/train
GET    /api/quantization/status/{job_id}
POST   /api/quantization/encode
POST   /api/quantization/decode
GET    /api/codebooks
POST   /api/codebooks/upload
POST   /api/comparison/metrics
GET    /api/performance/profile
```

---

## 9. Technology Stack

### Frontend
- **React 18+**: Component framework
- **Three.js**: 3D visualization
- **Redux**: State management
- **TypeScript**: Type safety
- **Electron**: Desktop application shell
- **TailwindCSS**: Styling

### Backend (C++23)
- **OpenMP**: Multi-threaded k-means
- **SIMD** (AVX2/AVX-512): Vectorized encoding/decoding
- **Eigen**: Linear algebra for rotation optimization
- **Protocol Buffers**: Data serialization
- **gtest**: Unit testing

### Data Pipeline
- **Arrow**: Columnar data format
- **Parquet**: Disk storage
- **HDF5**: Scientific computing format support
- **SQLite**: Metadata caching

---

## 10. Implementation Phases

### Phase 1: Core Quantization Engines (Weeks 1-3)
- [ ] ProductQuantizer with k-means
- [ ] ScalarQuantizer with linear mapping
- [ ] QualityMetrics (PSNR, SSIM, MSE)
- [ ] Unit tests for each quantizer
- **Deliverable:** Standalone C++ library with CLI

### Phase 2: Advanced Algorithms (Weeks 4-5)
- [ ] AdaptiveQuantizer with PU21 encoding
- [ ] StructuredQuantizer (OPQ) with rotation learning
- [ ] Batch encoding/decoding with SIMD
- [ ] Performance benchmarking suite

### Phase 3: UI Foundation (Weeks 6-7)
- [ ] Electron app skeleton
- [ ] Redux store for quantization state
- [ ] IPC bridge for C++ â†” TypeScript
- [ ] Basic forms for quantization control

### Phase 4: Visualization (Weeks 8-9)
- [ ] Three.js 3D rendering of vectors
- [ ] Error heatmap visualization
- [ ] Real-time metrics dashboard
- [ ] Camera controls (zoom, rotate, pan)

### Phase 5: Codebook Management (Weeks 10-11)
- [ ] Codebook serialization (JSON + Binary)
- [ ] Codebook library UI
- [ ] Training progress visualization
- [ ] Codebook validation and export

### Phase 6: Integration & Polish (Weeks 12-13)
- [ ] HEKTOR Core integration
- [ ] REST API endpoints
- [ ] Theme system and styling
- [ ] Keyboard shortcuts and accessibility

### Phase 7: Performance Optimization (Week 14)
- [ ] SIMD kernel optimization
- [ ] Memory profiling and tuning
- [ ] GPU acceleration (optional CUDA)
- [ ] Cache-aware algorithms

### Phase 8: Testing & Documentation (Week 15-16)
- [ ] Comprehensive test suite
- [ ] User documentation
- [ ] API documentation
- [ ] Performance benchmarks and reports

---

## 11. Testing Strategy

### 11.1 Unit Tests

**C++ Quantization Tests:**
```cpp
TEST(ProductQuantizer, TrainAndEncodeDecode) {
  // Load test vectors (1000 Ã— 768D)
  // Train PQ (M=8, K=256)
  // Encode a vector
  // Decode and check reconstruction error < threshold
  EXPECT_LT(reconstruction_error, 0.01f);
}

TEST(ProductQuantizer, BroadcastPerformance) {
  // Benchmark: encode 1M vectors
  // Expected: < 1 second (500ns per vector)
  EXPECT_LT(duration_ms, 1000);
}

TEST(PerceptualCurves, PU21Transform) {
  // Verify PU21 mapping for known values
  // Check monotonicity and differentiability
  EXPECT_LT(error, 0.001f);
}
```

**TypeScript/React Tests:**
```typescript
describe('QuantizationStore', () => {
  test('dispatch train action updates state', () => {
    const store = createStore();
    store.dispatch(startTraining({method: 'PQ', ...}));
    expect(store.getState().training.inProgress).toBe(true);
  });

  test('metrics dashboard updates on new data', () => {
    const {getByText} = render(<MetricsDashboard {...props} />);
    expect(getByText(/PSNR: 42.3/)).toBeInTheDocument();
  });
});
```

### 11.2 Integration Tests

**End-to-End Workflows:**
```
1. Load dataset (CSV)
   â†“
2. Configure quantization (PQ 8Ã—256)
   â†“
3. Train codebook
   â†“
4. Encode test vectors
   â†“
5. Verify metrics meet thresholds
   â†“
6. Export codebook
   â†“
7. Load codebook in new session
   â†“
8. Decode vectors with loaded codebook
   â†“
9. Verify identical results
```

### 11.3 Performance Tests

**Benchmark Suite:**
```
Encoding: 1M vectors Ã— 768D
â”œâ”€ Throughput: target 2M vectors/sec
â”œâ”€ Latency p99: target <2Âµs
â””â”€ Memory: target <100MB

Decoding: same metrics

K-means training: 100K vectors Ã— 768D
â”œâ”€ Training time: target <5 sec
â””â”€ Convergence: monitor loss curve

OPQ rotation learning: 50K vectors
â”œâ”€ Time per iteration: target <500ms
â””â”€ Total iterations: typically 3-5
```

### 11.4 Quality Tests

**Validation on Reference Datasets:**
- ImageNet embeddings (768D)
- Text embeddings (768D)
- Medical imaging (256D, 512D)

**Acceptance Criteria:**
- PSNR â‰¥ 40 dB
- SSIM â‰¥ 0.92
- Recall@10 â‰¥ 95%
- Compression â‰¥ 4x

---

## Conclusion

The HEKTOR Perceptual Quantization Studio combines cutting-edge vector compression algorithms with an intuitive, production-ready interface. By integrating perceptual quality metrics from HDR imaging, we achieve unprecedented compression-quality tradeoffs while maintaining semantic fidelity for ML applications.

This design positions HEKTOR as the industry leader in intelligent vector database quantization, enabling billion-scale deployments with sub-millisecond search latency and minimal memory footprint.

---

**Document End**  
*Size: 19.8 KB | Status: Complete | Version: 2.0*
