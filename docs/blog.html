<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Blog & Research - Hektor</title>
    <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><rect width=%22100%22 height=%22100%22 fill=%22white%22/></svg>">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&family=JetBrains+Mono:wght@400;500&family=Newsreader:ital,opsz,wght@0,6..72,300;0,6..72,400;0,6..72,500;1,6..72,300;1,6..72,400&display=swap" rel="stylesheet">
    <script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>
    <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }
        
        :root {
            --bg-primary: #09090b;
            --bg-elevated: #18181b;
            --bg-glass: rgba(255, 255, 255, 0.03);
            --bg-glass-hover: rgba(255, 255, 255, 0.06);
            --border-subtle: rgba(255, 255, 255, 0.08);
            --border-hover: rgba(251, 191, 36, 0.25);
            --text-primary: #fafafa;
            --text-secondary: #a1a1aa;
            --text-muted: #71717a;
            --accent-gold: #fbbf24;
            --accent-amber: #f59e0b;
            --accent-violet: #a78bfa;
            --accent-emerald: #34d399;
            --accent-rose: #fb7185;
        }

        html { scroll-behavior: smooth; }

        body {
            font-family: 'Inter', -apple-system, BlinkMacSystemFont, sans-serif;
            background-color: var(--bg-primary);
            color: var(--text-primary);
            line-height: 1.7;
            overflow-x: hidden;
            -webkit-font-smoothing: antialiased;
            -moz-osx-font-smoothing: grayscale;
        }

        .font-mono { font-family: 'JetBrains Mono', monospace; }
        .font-serif { font-family: 'Newsreader', Georgia, serif; }

        /* Ambient Background */
        .ambient-bg {
            position: fixed;
            inset: 0;
            z-index: -1;
            overflow: hidden;
            pointer-events: none;
        }

        .ambient-bg::before {
            content: '';
            position: absolute;
            top: -50%;
            left: -50%;
            width: 200%;
            height: 200%;
            background: 
                radial-gradient(ellipse at 20% 20%, rgba(251, 191, 36, 0.03) 0%, transparent 50%),
                radial-gradient(ellipse at 80% 80%, rgba(167, 139, 250, 0.02) 0%, transparent 50%),
                radial-gradient(ellipse at 50% 50%, rgba(52, 211, 153, 0.01) 0%, transparent 60%);
            animation: ambientDrift 30s ease-in-out infinite;
        }

        @keyframes ambientDrift {
            0%, 100% { transform: translate(0, 0) rotate(0deg); }
            33% { transform: translate(2%, 1%) rotate(1deg); }
            66% { transform: translate(-1%, 2%) rotate(-1deg); }
        }

        /* Navigation */
        nav {
            position: fixed;
            top: 0;
            left: 0;
            right: 0;
            z-index: 40;
            background: rgba(9, 9, 11, 0.85);
            backdrop-filter: blur(20px) saturate(180%);
            -webkit-backdrop-filter: blur(20px) saturate(180%);
            border-bottom: 1px solid var(--border-subtle);
        }

        nav .nav-inner {
            max-width: 1200px;
            margin: 0 auto;
            padding: 0 32px;
            display: flex;
            align-items: center;
            justify-content: space-between;
            height: 72px;
        }

        nav .logo {
            display: flex;
            align-items: center;
            gap: 12px;
            text-decoration: none;
            color: var(--text-primary);
            font-weight: 600;
            font-size: 17px;
            letter-spacing: -0.02em;
            transition: opacity 0.2s ease;
        }

        nav .logo:hover { opacity: 0.8; }

        nav .logo-box {
            width: 28px;
            height: 28px;
            border-radius: 6px;
            background: linear-gradient(135deg, var(--accent-gold), var(--accent-amber));
            box-shadow: 0 2px 8px rgba(251, 191, 36, 0.25);
        }

        nav .nav-links {
            display: flex;
            gap: 40px;
        }

        nav .nav-links a {
            color: var(--text-muted);
            text-decoration: none;
            font-size: 14px;
            font-weight: 500;
            letter-spacing: -0.01em;
            transition: color 0.2s ease;
            position: relative;
        }

        nav .nav-links a:hover { color: var(--text-primary); }

        nav .nav-links a.active {
            color: var(--accent-gold);
        }

        nav .nav-links a.active::after {
            content: '';
            position: absolute;
            bottom: -26px;
            left: 0;
            right: 0;
            height: 2px;
            background: var(--accent-gold);
            border-radius: 2px 2px 0 0;
        }

        /* Mobile Menu */
        .mobile-menu-btn {
            display: none;
            align-items: center;
            justify-content: center;
            width: 44px;
            height: 44px;
            border: none;
            background: transparent;
            cursor: pointer;
            color: var(--text-muted);
            border-radius: 8px;
            transition: all 0.2s ease;
        }

        .mobile-menu-btn:hover { 
            color: var(--text-primary);
            background: var(--bg-glass);
        }
        
        .mobile-menu-btn svg { width: 22px; height: 22px; }
        .mobile-menu-btn .close-icon { display: none; }
        .mobile-menu-btn.active .hamburger-icon { display: none; }
        .mobile-menu-btn.active .close-icon { display: block; }

        .mobile-sidebar {
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background: var(--bg-primary);
            z-index: 35;
            transform: translateX(-100%);
            transition: transform 0.3s cubic-bezier(0.4, 0, 0.2, 1);
            padding-top: 88px;
        }

        .mobile-sidebar.active { transform: translateX(0); }

        .mobile-sidebar-inner {
            padding: 24px 32px;
            display: flex;
            flex-direction: column;
            gap: 4px;
        }

        .mobile-sidebar a {
            color: var(--text-secondary);
            text-decoration: none;
            font-size: 18px;
            font-weight: 500;
            padding: 16px 0;
            border-bottom: 1px solid var(--border-subtle);
            transition: color 0.2s ease;
        }

        .mobile-sidebar a:hover,
        .mobile-sidebar a.active {
            color: var(--accent-gold);
        }

        /* Main Container */
        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 120px 32px 80px;
        }

        /* Hero Section */
        .hero {
            text-align: center;
            padding: 40px 0 80px;
            position: relative;
        }

        .hero-eyebrow {
            display: inline-flex;
            align-items: center;
            gap: 8px;
            font-size: 12px;
            font-weight: 600;
            text-transform: uppercase;
            letter-spacing: 0.1em;
            color: var(--accent-gold);
            margin-bottom: 20px;
        }

        .hero-eyebrow::before,
        .hero-eyebrow::after {
            content: '';
            width: 24px;
            height: 1px;
            background: linear-gradient(90deg, transparent, var(--accent-gold));
        }

        .hero-eyebrow::after {
            background: linear-gradient(90deg, var(--accent-gold), transparent);
        }

        .hero h1 {
            font-size: clamp(36px, 5vw, 56px);
            font-weight: 300;
            letter-spacing: -0.03em;
            line-height: 1.1;
            margin-bottom: 20px;
            color: var(--text-primary);
        }

        .hero h1 strong {
            font-weight: 600;
            background: linear-gradient(135deg, var(--accent-gold) 0%, var(--accent-violet) 100%);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
        }

        .hero p {
            font-family: 'Newsreader', Georgia, serif;
            font-size: 19px;
            color: var(--text-muted);
            max-width: 560px;
            margin: 0 auto;
            font-weight: 400;
            font-style: italic;
            line-height: 1.6;
        }

        /* Section Navigation */
        .section-nav {
            display: flex;
            justify-content: center;
            gap: 6px;
            margin-bottom: 64px;
            flex-wrap: wrap;
            background: var(--bg-glass);
            border: 1px solid var(--border-subtle);
            border-radius: 12px;
            padding: 6px;
            width: fit-content;
            margin-left: auto;
            margin-right: auto;
        }

        .section-nav button {
            padding: 10px 20px;
            background: transparent;
            border: none;
            border-radius: 8px;
            color: var(--text-muted);
            font-size: 13px;
            font-weight: 500;
            cursor: pointer;
            transition: all 0.2s ease;
            font-family: inherit;
            letter-spacing: -0.01em;
        }

        .section-nav button:hover {
            color: var(--text-secondary);
            background: rgba(255, 255, 255, 0.03);
        }

        .section-nav button.active {
            background: var(--bg-elevated);
            color: var(--text-primary);
            box-shadow: 0 2px 8px rgba(0, 0, 0, 0.3);
        }

        /* Content Sections */
        .content-section {
            display: none;
            animation: fadeIn 0.4s ease;
        }

        .content-section.active {
            display: block;
        }

        @keyframes fadeIn {
            from { opacity: 0; transform: translateY(12px); }
            to { opacity: 1; transform: translateY(0); }
        }

        /* Section Header */
        .section-header {
            margin-bottom: 48px;
            text-align: center;
        }

        .section-header h2 {
            font-size: 11px;
            font-weight: 600;
            text-transform: uppercase;
            letter-spacing: 0.15em;
            color: var(--text-muted);
            margin-bottom: 8px;
        }

        .section-header p {
            font-family: 'Newsreader', Georgia, serif;
            font-size: 17px;
            color: var(--text-secondary);
            font-weight: 400;
            font-style: italic;
        }

        /* Card Grid */
        .card-grid {
            display: grid;
            grid-template-columns: repeat(auto-fill, minmax(360px, 1fr));
            gap: 24px;
        }

        /* Blog Card - Distinct Style */
        .blog-card {
            background: linear-gradient(135deg, var(--bg-glass) 0%, rgba(251, 191, 36, 0.02) 100%);
            border: 1px solid var(--border-subtle);
            border-radius: 16px;
            padding: 32px;
            cursor: pointer;
            transition: all 0.3s cubic-bezier(0.4, 0, 0.2, 1);
            position: relative;
            overflow: hidden;
        }

        .blog-card::before {
            content: '';
            position: absolute;
            top: 0;
            left: 0;
            right: 0;
            height: 3px;
            background: linear-gradient(90deg, var(--accent-gold), var(--accent-violet));
            opacity: 0;
            transition: opacity 0.3s ease;
        }

        .blog-card:hover {
            background: var(--bg-glass-hover);
            border-color: var(--border-hover);
            transform: translateY(-4px);
            box-shadow: 0 20px 40px rgba(0, 0, 0, 0.3);
        }

        .blog-card:hover::before {
            opacity: 1;
        }

        .blog-card .card-date {
            font-size: 12px;
            color: var(--accent-gold);
            font-weight: 600;
            letter-spacing: 0.02em;
            margin-bottom: 12px;
            font-family: 'JetBrains Mono', monospace;
        }

        .blog-card h3 {
            font-size: 20px;
            font-weight: 600;
            color: var(--text-primary);
            margin-bottom: 12px;
            line-height: 1.35;
            letter-spacing: -0.02em;
        }

        .blog-card .card-description {
            font-family: 'Newsreader', Georgia, serif;
            font-size: 16px;
            color: var(--text-muted);
            line-height: 1.65;
            font-weight: 400;
        }

        .blog-card .read-more {
            display: inline-flex;
            align-items: center;
            gap: 6px;
            margin-top: 20px;
            font-size: 13px;
            font-weight: 500;
            color: var(--accent-gold);
            opacity: 0;
            transform: translateY(4px);
            transition: all 0.3s ease;
        }

        .blog-card:hover .read-more {
            opacity: 1;
            transform: translateY(0);
        }

        .read-more svg {
            width: 14px;
            height: 14px;
            transition: transform 0.2s ease;
        }

        .blog-card:hover .read-more svg {
            transform: translateX(3px);
        }

        /* Document Card - For Research/Articles */
        .doc-card {
            background: var(--bg-glass);
            border: 1px solid var(--border-subtle);
            border-radius: 16px;
            padding: 28px;
            cursor: pointer;
            transition: all 0.3s cubic-bezier(0.4, 0, 0.2, 1);
            position: relative;
            overflow: hidden;
        }

        .doc-card:hover {
            background: var(--bg-glass-hover);
            border-color: var(--border-hover);
            transform: translateY(-2px);
            box-shadow: 0 12px 32px rgba(0, 0, 0, 0.2);
        }

        .doc-card .card-meta {
            display: flex;
            align-items: center;
            gap: 10px;
            margin-bottom: 16px;
        }

        .doc-card .card-category {
            font-size: 10px;
            font-weight: 600;
            text-transform: uppercase;
            letter-spacing: 0.08em;
            color: var(--accent-gold);
            background: rgba(251, 191, 36, 0.12);
            padding: 5px 10px;
            border-radius: 6px;
        }

        .doc-card .card-order {
            font-size: 11px;
            color: var(--text-muted);
            font-family: 'JetBrains Mono', monospace;
        }

        .doc-card h3 {
            font-size: 17px;
            font-weight: 600;
            color: var(--text-primary);
            margin-bottom: 10px;
            line-height: 1.4;
            letter-spacing: -0.01em;
        }

        .doc-card .card-description {
            font-size: 14px;
            color: var(--text-muted);
            line-height: 1.6;
            margin-bottom: 20px;
        }

        .doc-card .card-footer {
            display: flex;
            align-items: center;
            justify-content: space-between;
            padding-top: 16px;
            border-top: 1px solid var(--border-subtle);
        }

        .doc-card .card-date {
            font-size: 12px;
            color: var(--text-muted);
            font-family: 'JetBrains Mono', monospace;
        }

        .doc-card .card-status {
            font-size: 10px;
            font-weight: 600;
            text-transform: uppercase;
            letter-spacing: 0.05em;
            padding: 4px 10px;
            border-radius: 6px;
            background: rgba(52, 211, 153, 0.12);
            color: var(--accent-emerald);
        }

        .doc-card .card-status.draft {
            background: rgba(251, 191, 36, 0.12);
            color: var(--accent-gold);
        }

        .doc-card .card-status.speculative {
            background: rgba(167, 139, 250, 0.12);
            color: var(--accent-violet);
        }

        /* Modal */
        .modal-overlay {
            position: fixed;
            inset: 0;
            background: rgba(0, 0, 0, 0.85);
            backdrop-filter: blur(12px);
            z-index: 100;
            display: none;
            align-items: flex-start;
            justify-content: center;
            padding: 40px 20px;
            overflow-y: auto;
        }

        .modal-overlay.active {
            display: flex;
        }

        .modal {
            background: var(--bg-primary);
            border: 1px solid var(--border-subtle);
            border-radius: 20px;
            width: 100%;
            max-width: 860px;
            max-height: calc(100vh - 80px);
            overflow: hidden;
            display: flex;
            flex-direction: column;
            animation: modalIn 0.35s cubic-bezier(0.4, 0, 0.2, 1);
            box-shadow: 0 25px 50px -12px rgba(0, 0, 0, 0.5);
        }

        @keyframes modalIn {
            from { opacity: 0; transform: translateY(24px) scale(0.97); }
            to { opacity: 1; transform: translateY(0) scale(1); }
        }

        .modal-header {
            padding: 28px 36px;
            border-bottom: 1px solid var(--border-subtle);
            display: flex;
            align-items: flex-start;
            justify-content: space-between;
            gap: 24px;
            background: var(--bg-elevated);
        }

        .modal-header h2 {
            font-size: 24px;
            font-weight: 600;
            color: var(--text-primary);
            line-height: 1.3;
            letter-spacing: -0.02em;
        }

        .modal-header .meta {
            font-size: 13px;
            color: var(--text-muted);
            margin-top: 8px;
            font-family: 'JetBrains Mono', monospace;
        }

        .modal-close {
            width: 40px;
            height: 40px;
            border: 1px solid var(--border-subtle);
            border-radius: 10px;
            background: transparent;
            color: var(--text-muted);
            cursor: pointer;
            display: flex;
            align-items: center;
            justify-content: center;
            transition: all 0.2s ease;
            flex-shrink: 0;
        }

        .modal-close:hover {
            border-color: var(--accent-gold);
            color: var(--accent-gold);
            background: rgba(251, 191, 36, 0.1);
        }

        .modal-content {
            padding: 40px;
            overflow-y: auto;
            flex: 1;
        }

        /* Article Typography - Enhanced */
        .article-content {
            font-family: 'Newsreader', Georgia, serif;
            font-size: 18px;
            line-height: 1.85;
            color: var(--text-secondary);
        }

        .article-content > *:first-child {
            margin-top: 0 !important;
        }

        .article-content h1,
        .article-content h2,
        .article-content h3,
        .article-content h4,
        .article-content h5,
        .article-content h6 {
            font-family: 'Inter', sans-serif;
            color: var(--text-primary);
            margin-top: 2.5em;
            margin-bottom: 0.75em;
            line-height: 1.3;
            letter-spacing: -0.02em;
        }

        .article-content h1 { 
            font-size: 32px; 
            font-weight: 600;
            padding-bottom: 16px;
            border-bottom: 1px solid var(--border-subtle);
        }
        .article-content h2 { 
            font-size: 24px; 
            font-weight: 600;
            color: var(--accent-gold);
        }
        .article-content h3 { font-size: 20px; font-weight: 600; }
        .article-content h4 { font-size: 17px; font-weight: 600; }

        .article-content p {
            margin-bottom: 1.5em;
        }

        .article-content strong {
            color: var(--text-primary);
            font-weight: 600;
        }

        .article-content em {
            font-style: italic;
        }

        .article-content a {
            color: var(--accent-gold);
            text-decoration: none;
            border-bottom: 1px solid rgba(251, 191, 36, 0.3);
            transition: all 0.2s ease;
        }

        .article-content a:hover {
            border-color: var(--accent-gold);
            background: rgba(251, 191, 36, 0.1);
        }

        .article-content code {
            font-family: 'JetBrains Mono', monospace;
            font-size: 0.85em;
            background: rgba(251, 191, 36, 0.1);
            padding: 3px 7px;
            border-radius: 5px;
            color: var(--accent-gold);
            border: 1px solid rgba(251, 191, 36, 0.15);
        }

        .article-content pre {
            background: #0d0d0f;
            border: 1px solid var(--border-subtle);
            border-radius: 12px;
            padding: 24px;
            overflow-x: auto;
            margin: 2em 0;
        }

        .article-content pre code {
            background: none;
            padding: 0;
            font-size: 14px;
            color: var(--text-secondary);
            border: none;
            line-height: 1.6;
        }

        .article-content blockquote {
            border-left: 3px solid var(--accent-gold);
            padding: 16px 24px;
            margin: 2em 0;
            background: rgba(251, 191, 36, 0.05);
            border-radius: 0 12px 12px 0;
            color: var(--text-secondary);
            font-style: italic;
        }

        .article-content blockquote p:last-child {
            margin-bottom: 0;
        }

        .article-content ul,
        .article-content ol {
            margin: 1.5em 0;
            padding-left: 1.5em;
        }

        .article-content li {
            margin-bottom: 0.75em;
        }

        .article-content li::marker {
            color: var(--accent-gold);
        }

        .article-content table {
            width: 100%;
            border-collapse: collapse;
            margin: 2em 0;
            font-family: 'Inter', sans-serif;
            font-size: 14px;
        }

        .article-content th,
        .article-content td {
            padding: 14px 18px;
            border: 1px solid var(--border-subtle);
            text-align: left;
        }

        .article-content th {
            background: var(--bg-elevated);
            font-weight: 600;
            color: var(--text-primary);
            font-size: 12px;
            text-transform: uppercase;
            letter-spacing: 0.05em;
        }

        .article-content tr:hover td {
            background: rgba(255, 255, 255, 0.02);
        }

        .article-content hr {
            border: none;
            border-top: 1px solid var(--border-subtle);
            margin: 3em 0;
        }

        .article-content img {
            max-width: 100%;
            border-radius: 12px;
            margin: 2em 0;
        }

        /* Loading State */
        .loading-spinner {
            display: flex;
            align-items: center;
            justify-content: center;
            padding: 60px;
            color: var(--text-muted);
            gap: 12px;
        }

        .loading-spinner::before {
            content: '';
            width: 20px;
            height: 20px;
            border: 2px solid var(--border-subtle);
            border-top-color: var(--accent-gold);
            border-radius: 50%;
            animation: spin 0.8s linear infinite;
        }

        @keyframes spin {
            to { transform: rotate(360deg); }
        }

        /* Responsive */
        @media (max-width: 768px) {
            nav .nav-links { display: none; }
            .mobile-menu-btn { display: flex; }
            
            .container { padding: 100px 20px 60px; }
            
            .hero { padding: 24px 0 60px; }
            .hero h1 { font-size: 32px; }
            .hero p { font-size: 17px; }
            
            .card-grid { grid-template-columns: 1fr; gap: 16px; }
            
            .blog-card, .doc-card { padding: 24px; }
            
            .modal { 
                margin: 12px; 
                max-height: calc(100vh - 24px);
                border-radius: 16px;
            }
            .modal-header { padding: 20px 24px; }
            .modal-header h2 { font-size: 20px; }
            .modal-content { padding: 24px; }
            
            .section-nav { 
                width: 100%;
                flex-wrap: wrap;
            }
            .section-nav button { 
                flex: 1;
                min-width: 80px;
                padding: 10px 12px;
                font-size: 12px;
            }

            .article-content { font-size: 17px; }
            .article-content h1 { font-size: 26px; }
            .article-content h2 { font-size: 21px; }
        }
    </style>
</head>
<body>
    <div class="ambient-bg"></div>

    <!-- Mobile Sidebar -->
    <div class="mobile-sidebar" id="mobile-sidebar">
        <div class="mobile-sidebar-inner">
            <a href="index.html">Home</a>
            <a href="hektor.html">Overview</a>
            <a href="https://artifact-virtual.gitbook.io/hektor/">Docs</a>
            <a href="blog.html" class="active">Blog</a>
            <a href="https://github.com/amuzetnoM/hektor.git">GitHub</a>
        </div>
    </div>

    <!-- Navigation -->
    <nav>
        <div class="nav-inner">
            <a href="index.html" class="logo">
                <div class="logo-box"></div>
                <span>HEKTOR</span>
            </a>
            <div class="nav-links">
                <a href="hektor.html">Overview</a>
                <a href="https://artifact-virtual.gitbook.io/hektor/">Docs</a>
                <a href="blog.html" class="active">Blog</a>
                <a href="https://github.com/amuzetnoM/hektor.git">GitHub</a>
            </div>
            <button class="mobile-menu-btn" id="mobile-menu-btn">
                <svg class="hamburger-icon" stroke="currentColor" fill="none" viewBox="0 0 24 24">
                    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M4 6h16M4 12h16M4 18h16"/>
                </svg>
                <svg class="close-icon" stroke="currentColor" fill="none" viewBox="0 0 24 24">
                    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M6 18L18 6M6 6l12 12"/>
                </svg>
            </button>
        </div>
    </nav>

    <div class="container">
        <!-- Hero -->
        <div class="hero">
            <div class="hero-eyebrow">Research & Insights</div>
            <h1>Building <strong>Hektor</strong></h1>
            <p>Notes from the frontier of vector databases, perceptual quantization, and high-dimensional search.</p>
        </div>

        <!-- Section Navigation -->
        <div class="section-nav">
            <button class="active" data-section="blog">Blog</button>
            <button data-section="articles">Articles</button>
            <button data-section="research">Research</button>
            <button data-section="publications">Publications</button>
        </div>

        <!-- Blog Section -->
        <div class="content-section active" id="blog-section">
            <div class="section-header">
                <h2>Developer Blog</h2>
                <p>Personal notes, decisions, and lessons from building Hektor</p>
            </div>
            <div class="card-grid" id="blog-grid"></div>
        </div>

        <!-- Articles Section -->
        <div class="content-section" id="articles-section">
            <div class="section-header">
                <h2>Technical Articles</h2>
                <p>Deep explorations into advanced topics and emerging research</p>
            </div>
            <div class="card-grid" id="articles-grid"></div>
        </div>

        <!-- Research Section -->
        <div class="content-section" id="research-section">
            <div class="section-header">
                <h2>Research Papers</h2>
                <p>Foundational research on algorithms, theory, and implementation</p>
            </div>
            <div class="card-grid" id="research-grid"></div>
        </div>

        <!-- Publications Section -->
        <div class="content-section" id="publications-section">
            <div class="section-header">
                <h2>Publications</h2>
                <p>Surveys, standards, and comprehensive analyses</p>
            </div>
            <div class="card-grid" id="publications-grid"></div>
        </div>
    </div>

    <!-- Modal -->
    <div class="modal-overlay" id="modal-overlay">
        <div class="modal">
            <div class="modal-header">
                <div>
                    <h2 id="modal-title"></h2>
                    <div class="meta" id="modal-meta"></div>
                </div>
                <button class="modal-close" id="modal-close">
                    <svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                        <path d="M18 6L6 18M6 6l12 12"/>
                    </svg>
                </button>
            </div>
            <div class="modal-content">
                <div class="article-content" id="modal-content"></div>
            </div>
        </div>
    </div>

    <script>
        // Configure marked for better rendering
        marked.setOptions({
            gfm: true,
            breaks: true,
            headerIds: true,
            mangle: false
        });

        // Document Data
        const documents = {
            blog: [
                {
                    id: 'the-beginning',
                    title: 'The Beginning: Why We Started Building Hektor',
                    description: 'Every project starts with frustration. Ours was with existing vector databases — too slow, too complex, too many compromises.',
                    date: '2025-11-15',
                    category: 'Origins',
                    status: 'Published',
                    order: 1,
                    content: `# The Beginning: Why We Started Building Hektor

*November 15, 2025*

---

Every meaningful project starts with frustration. Ours began on a cold November night, staring at benchmark results that made no sense.

We'd been evaluating vector databases for a project. Pinecone. Milvus. Qdrant. FAISS. Each one excellent in its own way. Each one missing something we needed.

## The Problem

What we wanted was simple:

1. **Sub-millisecond search** at scale (millions of vectors)
2. **High recall** (99%+ wasn't negotiable)
3. **Hybrid search** — vectors + full-text, unified
4. **Production-ready** — not a research prototype

No single solution hit all four. FAISS was fast but didn't do hybrid search. Milvus had features but latency was unpredictable. Qdrant was elegant but we needed more control over quantization.

## The Decision

So we did what engineers do when tools don't exist: we decided to build one.

The name came easily. **Hektor** — the defender. In the Iliad, Hektor was the Trojan hero who stood against impossible odds. Our Hektor would defend against the chaos of unstructured data, the flood of embeddings that modern AI systems generate.

## What We're Building

The architecture crystallized over a few whiteboard sessions:

- **C++23 core** — no compromises on performance
- **HNSW index** — the best algorithm for approximate nearest neighbor
- **Perceptual quantization** — compress intelligently, not blindly
- **Hybrid search engine** — BM25 + vectors, fused properly
- **Python bindings** — because the world runs on Python

We're not trying to replace everything. We're building something that does fewer things, but does them exceptionally well.

## What's Next

This blog will document the journey. The decisions that worked, the mistakes we made, the algorithms we implemented wrong three times before getting them right.

Building in public is terrifying. But it's also the only way to build something that matters.

Let's see where this goes.

---

*— The Hektor Team*`
                },
                {
                    id: 'choosing-hnsw',
                    title: 'Why HNSW Won: Choosing Our Index Algorithm',
                    description: 'We evaluated every major ANN algorithm. Here\'s why Hierarchical Navigable Small World graphs came out on top.',
                    date: '2025-12-03',
                    category: 'Architecture',
                    status: 'Published',
                    order: 2,
                    content: `# Why HNSW Won: Choosing Our Index Algorithm

*December 3, 2025*

---

Choosing an index algorithm is like choosing a foundation for a house. Get it wrong, and everything built on top will be compromised.

We spent three weeks evaluating options. Here's what we learned.

## The Contenders

### KD-Trees
The classic. Beautiful in low dimensions (≤20). Falls apart spectacularly above that. We're dealing with 384-512 dimensional vectors. Next.

### LSH (Locality-Sensitive Hashing)
Probabilistic guarantees sound good in papers. In practice, you need multiple hash tables to get decent recall, which eats memory. The parameter tuning is also dark magic — \`k\` hash functions, \`L\` tables, and pray.

### IVF (Inverted File Index)
FAISS made this popular. You cluster your data, then search relevant clusters. Fast builds. Good for batch workloads. But for real-time search with frequent updates? The cluster assignments become stale. Rebalancing is expensive.

### HNSW
A graph where every node connects to its approximate nearest neighbors, organized in hierarchical layers. Like a skip list, but for metric spaces.

## Why HNSW Won

The numbers spoke for themselves:

| Algorithm | Recall@10 | QPS (1M vectors) | Memory Overhead |
|-----------|-----------|------------------|-----------------|
| IVF-PQ | 0.89 | 12,000 | Low |
| LSH | 0.85 | 8,000 | High |
| HNSW | 0.98 | 5,500 | Medium |

HNSW had the highest recall. Not the fastest raw QPS, but fast enough — and when you factor in that IVF needs reranking to match HNSW's recall, the gap closes.

But the real winner was **operational simplicity**.

## The Operational Argument

HNSW has two main parameters:
- \`M\`: connections per node (we use 16)
- \`ef_search\`: search queue size (we use 200)

That's it. No cluster count to tune. No hash function parameters. No periodic rebalancing.

When a new vector comes in, we insert it. Takes ~2ms. The graph stays balanced automatically because of how the layers are structured.

For a production system, this simplicity is gold.

## Our Implementation

We wrote HNSW from scratch in C++23. Using hnswlib was tempting, but we needed:

1. **SIMD distance functions** — AVX-512 makes a 4x difference
2. **Custom memory layout** — cache-friendly node storage
3. **Concurrent reads during writes** — no global locks

The implementation took six weeks. Worth every hour.

## What We'd Do Differently

If we were building for 10B+ vectors, we'd probably use a hybrid approach — IVF for coarse partitioning, HNSW within partitions. But for our target scale (millions to low billions), pure HNSW is the right call.

---

*Next week: The perceptual quantization rabbit hole. It goes deep.*`
                },
                {
                    id: 'quantization-deep-dive',
                    title: 'The Quantization Rabbit Hole',
                    description: 'We thought compression was simple. Then we discovered perceptual curves, display-aware encoding, and the beautiful math of human vision.',
                    date: '2025-12-18',
                    category: 'Deep Dive',
                    status: 'Published',
                    order: 3,
                    content: `# The Quantization Rabbit Hole

*December 18, 2025*

---

"We just need to compress the vectors a bit."

Famous last words.

What started as a simple optimization became a three-week journey through perceptual science, color theory, and the mathematics of human vision. Here's what we learned.

## The Naive Approach

Standard vector quantization is straightforward:

1. Take your 512-dimensional float32 vectors (2KB each)
2. Quantize to int8 using scalar quantization (512 bytes each)
3. Save 75% memory

This works. Recall drops from 99.7% to ~95%. Acceptable for some use cases.

But we wanted better.

## Enter Product Quantization

The key insight: divide your vector into subvectors, quantize each independently.

\`\`\`
512-dim vector → 8 subvectors of 64 dims each
Each subvector → mapped to one of 256 centroids
Result: 8 bytes instead of 2048 bytes (256x compression!)
\`\`\`

The magic is in training the centroids. You cluster your subvectors using k-means, and the centroids capture the structure of your data.

We implemented this. Recall: 97%. Memory: 8 bytes per vector.

But then someone asked: *"What if perception matters?"*

## The Perceptual Revelation

Here's a fact that broke my brain: human perception of intensity is **logarithmic**, not linear.

The difference between 0 and 1 (luminance) looks the same as 10 and 11 to a meter. But to your eyes, 0→1 is a massive change while 10→11 is barely noticeable.

This is the Weber-Fechner law. And it means: **uniform quantization wastes bits**.

If you allocate equal precision across the range, you're over-representing changes humans can't perceive and under-representing changes they can.

## PQ Curves and HDR

The video industry solved this decades ago with Perceptual Quantizer (PQ) curves — SMPTE ST.2084.

The curve maps linear luminance to a perceptually uniform space:

\`\`\`
PQ(Y) = ((c₁ + c₂·Y^m₁) / (1 + c₃·Y^m₁))^m₂
\`\`\`

We adapted this for vectors. Instead of luminance, we apply perceptual curves to embedding magnitudes. Dimensions with high variance get more precision. Dimensions near zero get less.

Result: 98.5% recall at the same 8 bytes per vector.

## Display-Aware Encoding

This is where it gets wild.

Different displays have different capabilities:
- SDR monitors: 100 nits peak
- HDR10: 1000 nits
- HDR4000: 4000 nits

We built a \`DisplayAwareQuantizer\` that adapts encoding based on target display characteristics. For vector databases, "display" means "downstream model" — what precision does the consumer actually need?

A lightweight retrieval model doesn't need the same precision as a fine-grained reranker.

## The Implementation

Our final quantization system:

\`\`\`cpp
namespace vdb::quantization {
    class ProductQuantizer;       // Standard PQ
    class ScalarQuantizer;        // Simple 8-bit
    class DisplayAwareQuantizer;  // Perceptual curves
    class AdaptiveQuantizer;      // Learns from data
}
\`\`\`

Each has its place:
- **ProductQuantizer**: Maximum compression, good recall
- **ScalarQuantizer**: Fast, simple, baseline
- **DisplayAwareQuantizer**: When perception matters
- **AdaptiveQuantizer**: When you have training data

## What We Learned

Compression isn't about throwing away data. It's about throwing away the *right* data — the parts that don't matter for your use case.

In images, that's imperceptible details.
In audio, that's inaudible frequencies.
In vectors, that's... well, we're still figuring that out.

But the journey was worth it. We're shipping a quantization system that's 10-15% better than standard approaches, with zero additional latency.

---

*Sometimes the rabbit hole is the destination.*`
                },
                {
                    id: 'hybrid-search-journey',
                    title: 'Hybrid Search: Where Vectors Meet Words',
                    description: 'Pure semantic search misses keywords. Pure keyword search misses meaning. The solution requires both.',
                    date: '2026-01-05',
                    category: 'Architecture',
                    status: 'Published',
                    order: 4,
                    content: `# Hybrid Search: Where Vectors Meet Words

*January 5, 2026*

---

A user searched for "Apple M3 chip performance benchmarks" and got results about fruit orchards.

This is the semantic search failure mode. The embedding model understood "Apple" as a general concept but missed that in this context, it's a company name. It understood "chip" but associated it with potato chips in some training examples.

Pure semantic search is amazing. Until it isn't.

## The Keyword Problem

Meanwhile, traditional search has the opposite problem. Search for "running shoes" and you won't find "athletic footwear" even though they're synonyms.

Keywords are precise but brittle.
Semantics are flexible but imprecise.

The answer, obviously, is both.

## Building BM25 From Scratch

BM25 (Best Match 25) is the algorithm behind Elasticsearch, Lucene, and most production search systems. The formula looks scary:

\`\`\`
score(D, Q) = Σ IDF(qi) · (f(qi, D) · (k₁ + 1)) / (f(qi, D) + k₁ · (1 - b + b · |D|/avgdl))
\`\`\`

But it's really just three intuitions:
1. **IDF**: Rare terms matter more ("the" appears everywhere, ignore it)
2. **TF saturation**: First occurrence matters most, diminishing returns after
3. **Length normalization**: Don't bias toward longer documents

We implemented BM25 in C++ with:
- Porter stemming
- Stop word removal  
- Inverted index with posting lists

Search over 1M documents: 8ms. Fast enough.

## The Fusion Problem

Now you have two lists of results:
1. Vector search: results ranked by cosine similarity
2. BM25 search: results ranked by relevance score

How do you combine them?

### Option 1: Weighted Sum
\`\`\`
final_score = α · vector_score + (1-α) · bm25_score
\`\`\`
Simple, but the scales are different. BM25 scores might be 0-20, while cosine similarity is 0-1.

### Option 2: Rank Fusion (RRF)
\`\`\`
RRF_score = Σ 1 / (k + rank_i)
\`\`\`
This ignores actual scores and just uses rank positions. Surprisingly effective.

### Option 3: Learned Fusion
Train a model to combine scores. More complex, potentially better, requires training data.

We implemented all three. **RRF won for simplicity**. With k=60, it handles most cases well. For power users, we expose the weighted sum with configurable α.

## When Hybrid Shines

Hybrid search crushes pure approaches when queries contain:

- **Named entities**: "NVIDIA 4090 vs AMD 7900 XTX"
- **Product codes**: "iPhone 15 Pro Max A17"
- **Technical terms**: "HNSW ef_construction parameter"
- **Mixed intent**: "best practices kubernetes secrets" (concept + keyword)

For pure conceptual queries ("what is the meaning of life"), vector search alone is fine. For pure keyword queries ("error code 0x8007007E"), BM25 alone is fine.

Hybrid handles everything in between.

## The API

\`\`\`python
results = db.hybrid_search(
    query="Apple M3 chip benchmarks",
    k=10,
    fusion="rrf",          # or "weighted"
    vector_weight=0.7,     # for weighted fusion
    lexical_weight=0.3
)
\`\`\`

Clean and simple. The complexity is hidden where it should be.

## Lessons Learned

1. **Don't choose between paradigms** — combine them
2. **RRF is underrated** — rank-based fusion is robust and simple
3. **Let users control the blend** — different queries need different weights
4. **Keyword matching isn't dead** — it's a feature, not a bug

---

*Two weeks until v4.0 release. The finish line is in sight.*`
                },
                {
                    id: 'release-day',
                    title: 'Release Day: Hektor 4.0 is Live',
                    description: 'After months of building, testing, and refining — we shipped. Here\'s what\'s in the box and what comes next.',
                    date: '2026-01-22',
                    category: 'Release',
                    status: 'Published',
                    order: 5,
                    content: `# Release Day: Hektor 4.0 is Live

*January 22, 2026*

---

We shipped.

After four months of architecture, implementation, debugging, and more debugging — Hektor 4.0 is live.

## What's in the Box

### Core Engine (C++23)
- **HNSW Index**: Sub-millisecond search at 99%+ recall
- **SIMD Optimized**: AVX-512 distance functions (8x speedup)
- **Memory-Mapped Storage**: Handles datasets larger than RAM

### Hybrid Search
- **BM25 Engine**: Full-text search with proper linguistics
- **RRF Fusion**: Rank-based score combination
- **Query Rewriting**: Synonym expansion, spell correction

### Quantization System
- **Product Quantizer**: 8-32x compression
- **Perceptual Curves**: PQ, HLG, adaptive gamma
- **Display-Aware Encoding**: Downstream-optimized precision

### Integrations
- **Python Bindings**: First-class pyvdb module
- **REST API**: FastAPI server with JWT auth
- **OpenTelemetry**: Distributed tracing built-in

### Extras
- **LLM Engine**: Local inference via llama.cpp
- **RAG Toolkit**: Chunking, context building, reranking
- **Multi-format Ingest**: CSV, JSON, PDF, Excel, Parquet, and more

## The Numbers

Benchmarked on SIFT-1M (1 million 128-dim vectors):

| Metric | Hektor 4.0 |
|--------|------------|
| Recall@10 | 99.2% |
| Query Latency (p99) | 2.8ms |
| Build Time | 45 seconds |
| Memory | 1.2 GB |

We're competitive with the best open-source options and beat several commercial offerings.

## What We Learned

**The hard parts weren't where we expected.**

Memory management? Straightforward.
SIMD optimization? Tedious but tractable.
HNSW implementation? Well-documented.

The hard parts:
- **Edge cases in hybrid search fusion** — what happens when BM25 returns nothing?
- **Unicode handling in tokenization** — three weeks of pain
- **Cross-platform builds** — CMake is powerful and frustrating

**Tests save you.** We have 200+ test cases. Every one caught a real bug.

**Docs are a feature.** We spent 20% of our time on documentation. It shows.

## What's Next

This is 4.0, not 1.0 that we're calling 4.0 for marketing. It's genuinely the fourth major architecture.

For 4.1:
- GPU acceleration for embedding generation
- Distributed mode (sharding + replication)
- Improved adaptive quantization

For 5.0 (someday):
- Neural index structures
- End-to-end differentiable search
- Things we haven't imagined yet

## Thank You

To everyone who gave feedback, reported bugs, asked hard questions — thank you. Building in public is only possible because people engage.

The code is MIT licensed. The research is open. Use it, break it, improve it.

---

*This is just the beginning.*

\`\`\`bash
pip install pyvdb
\`\`\`

*Let's build something great.*

— *The Hektor Team*`
                }
            ],
            articles: [
                {
                    id: 'neural-latent-quantization',
                    title: 'Neural Latent Quantization: Learning Optimal Perceptual Bases',
                    description: 'Exploring semantic-space quantization where bits follow meaning rather than amplitude using learned latent representations.',
                    date: '2026-01-20',
                    category: 'Advanced Research',
                    status: 'Research',
                    order: 1,
                    file: 'RESEARCH/neural_latent_quantization.md'
                },
                {
                    id: 'temporal-redundancy',
                    title: 'Temporal Redundancy Beyond Motion Vectors',
                    description: 'Research on event-based encoding, delta-saliency, and memory-aware streaming for perceptual change encoding.',
                    date: '2026-01-20',
                    category: 'Advanced Research',
                    status: 'Research',
                    order: 2,
                    file: 'RESEARCH/temporal_redunduncy.md'
                },
                {
                    id: 'quantum-quantization',
                    title: 'Quantum Quantization: Superposition-Based Compression',
                    description: 'Theoretical framework for data compression using quantum computing principles including superposition and entanglement.',
                    date: '2026-01-20',
                    category: 'Theoretical',
                    status: 'Speculative',
                    order: 3,
                    file: 'RESEARCH/quantum_quantization.md'
                }
            ],
            research: [
                {
                    id: 'vector-space-theory',
                    title: 'Vector Space Theory in High-Dimensional Embeddings',
                    description: 'Comprehensive mathematical treatment of vector spaces, distance metrics, and their implications for similarity search.',
                    date: '2026-01-04',
                    category: 'Foundations',
                    status: 'Peer-Reviewed',
                    order: 1,
                    file: 'RESEARCH/vector_space_theory.md'
                },
                {
                    id: 'hnsw-algorithm',
                    title: 'HNSW Graphs: Theory, Implementation, and Analysis',
                    description: 'Complete treatment of Hierarchical Navigable Small World graphs for approximate nearest neighbor search.',
                    date: '2026-01-04',
                    category: 'Algorithms',
                    status: 'Peer-Reviewed',
                    order: 2,
                    file: 'RESEARCH/hnsw_algorithm.md'
                },
                {
                    id: 'perceptual-quantization',
                    title: 'Perceptual Quantization: Research & Implementation',
                    description: 'Theoretical foundations and practical applications of perceptual quantization for vector compression.',
                    date: '2026-01-04',
                    category: 'Quantization',
                    status: 'Peer-Reviewed',
                    order: 3,
                    file: 'RESEARCH/perceptual_quantization.md'
                }
            ],
            publications: [
                {
                    id: 'research-survey',
                    title: 'Research Survey: State-of-the-Art in Vector Databases',
                    description: 'Comprehensive overview of 50+ papers covering vector databases, similarity search, and embeddings from 1954-2026.',
                    date: '2026-01-04',
                    category: 'Survey',
                    status: 'Published',
                    order: 1,
                    file: 'RESEARCH/papers/research_survey.md'
                },
                {
                    id: 'opentelemetry-tracing',
                    title: 'OpenTelemetry Distributed Tracing: 2026 Standards',
                    description: 'Comprehensive analysis of OpenTelemetry distributed tracing following AWS X-Ray\'s transition to OTel.',
                    date: '2026-01-08',
                    category: 'Systems',
                    status: 'Peer-Reviewed',
                    order: 2,
                    file: 'RESEARCH/papers/opentelemetry_distributed_tracing_2026.md'
                }
            ]
        };

        // Render blog cards (different style)
        function renderBlogCards(containerId) {
            const container = document.getElementById(containerId);
            const items = documents.blog.sort((a, b) => new Date(b.date) - new Date(a.date)); // Newest first
            
            container.innerHTML = items.map(doc => `
                <div class="blog-card" data-id="${doc.id}" data-section="blog">
                    <div class="card-date">${formatDate(doc.date)}</div>
                    <h3>${doc.title}</h3>
                    <p class="card-description">${doc.description}</p>
                    <div class="read-more">
                        Read more
                        <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                            <path d="M5 12h14M12 5l7 7-7 7"/>
                        </svg>
                    </div>
                </div>
            `).join('');

            container.querySelectorAll('.blog-card').forEach(card => {
                card.addEventListener('click', () => openModal('blog', card.dataset.id));
            });
        }

        // Render document cards
        function renderDocCards(section, containerId) {
            const container = document.getElementById(containerId);
            const items = documents[section].sort((a, b) => a.order - b.order);
            
            if (items.length === 0) {
                container.innerHTML = `
                    <div style="text-align: center; padding: 60px; color: var(--text-muted);">
                        <p>No content available yet.</p>
                    </div>
                `;
                return;
            }

            container.innerHTML = items.map(doc => {
                const statusClass = doc.status.toLowerCase().includes('speculative') ? 'speculative' : 
                                   doc.status.toLowerCase().includes('draft') || doc.status.toLowerCase().includes('research') ? 'draft' : '';
                return `
                    <div class="doc-card" data-id="${doc.id}" data-section="${section}">
                        <div class="card-meta">
                            <span class="card-category">${doc.category}</span>
                            <span class="card-order">#${String(doc.order).padStart(2, '0')}</span>
                        </div>
                        <h3>${doc.title}</h3>
                        <p class="card-description">${doc.description}</p>
                        <div class="card-footer">
                            <span class="card-date">${formatDate(doc.date)}</span>
                            <span class="card-status ${statusClass}">${doc.status}</span>
                        </div>
                    </div>
                `;
            }).join('');

            container.querySelectorAll('.doc-card').forEach(card => {
                card.addEventListener('click', () => openModal(card.dataset.section, card.dataset.id));
            });
        }

        function formatDate(dateStr) {
            const date = new Date(dateStr);
            return date.toLocaleDateString('en-US', { month: 'long', day: 'numeric', year: 'numeric' });
        }

        // Modal handling
        async function openModal(section, id) {
            const doc = documents[section].find(d => d.id === id);
            if (!doc) return;

            document.getElementById('modal-title').textContent = doc.title;
            document.getElementById('modal-meta').textContent = `${doc.category} · ${formatDate(doc.date)}`;
            
            // Show loading state
            document.getElementById('modal-content').innerHTML = '<div class="loading-spinner">Loading article...</div>';
            document.getElementById('modal-overlay').classList.add('active');
            document.body.style.overflow = 'hidden';
            
            let content = doc.content;
            
            // If no inline content, try to fetch from file
            if (!content && doc.file) {
                try {
                    const response = await fetch(doc.file);
                    if (response.ok) {
                        content = await response.text();
                        // Remove YAML frontmatter
                        content = content.replace(/^---[\s\S]*?---\s*/m, '');
                    } else {
                        throw new Error(`HTTP ${response.status}`);
                    }
                } catch (e) {
                    console.error('Fetch error:', e);
                    content = `# ${doc.title}

> This paper is available at \`${doc.file}\`

## Abstract

${doc.description}

---

**Note**: To view the full research paper, please serve this page via HTTP:

\`\`\`bash
cd docs
python -m http.server 8000
\`\`\`

Then open [http://localhost:8000/blog.html](http://localhost:8000/blog.html)

---

*Direct file:// access is restricted by browser security policies.*`;
                }
            }
            
            document.getElementById('modal-content').innerHTML = marked.parse(content || '*No content available.*');
        }

        function closeModal() {
            document.getElementById('modal-overlay').classList.remove('active');
            document.body.style.overflow = '';
        }

        // Section navigation
        document.querySelectorAll('.section-nav button').forEach(btn => {
            btn.addEventListener('click', () => {
                document.querySelectorAll('.section-nav button').forEach(b => b.classList.remove('active'));
                btn.classList.add('active');
                
                document.querySelectorAll('.content-section').forEach(s => s.classList.remove('active'));
                document.getElementById(`${btn.dataset.section}-section`).classList.add('active');
            });
        });

        // Modal close handlers
        document.getElementById('modal-close').addEventListener('click', closeModal);
        document.getElementById('modal-overlay').addEventListener('click', (e) => {
            if (e.target === e.currentTarget) closeModal();
        });
        document.addEventListener('keydown', (e) => {
            if (e.key === 'Escape') closeModal();
        });

        // Mobile menu
        const mobileMenuBtn = document.getElementById('mobile-menu-btn');
        const mobileSidebar = document.getElementById('mobile-sidebar');
        
        mobileMenuBtn.addEventListener('click', () => {
            mobileMenuBtn.classList.toggle('active');
            mobileSidebar.classList.toggle('active');
        });

        mobileSidebar.querySelectorAll('a').forEach(link => {
            link.addEventListener('click', () => {
                mobileMenuBtn.classList.remove('active');
                mobileSidebar.classList.remove('active');
            });
        });

        // Initialize
        renderBlogCards('blog-grid');
        renderDocCards('articles', 'articles-grid');
        renderDocCards('research', 'research-grid');
        renderDocCards('publications', 'publications-grid');
    </script>
</body>
</html>
