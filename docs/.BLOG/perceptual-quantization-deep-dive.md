# Perceptual Quantization: How Hektor Compresses Like Hollywood

*January 24, 2026*

---

When I tell people Hektor uses "perceptual quantization," I get two reactions:

1. **"What does that even mean?"**
2. **"Wait, like Dolby Vision? In a vector database?"**

The answer to both: yes, exactly like Dolby Vision, and here's why it matters.

## The Problem with Standard Quantization

Every vector database needs to compress vectors. A million 1536-dimensional float32 embeddings takes 5.7GB of RAM. That's not sustainable.

Standard approaches:
- **Scalar Quantization (SQ)**: Map floats to int8. 4x compression, 1-2% recall loss.
- **Product Quantization (PQ)**: Cluster subvectors, store cluster IDs. 8-32x compression, 2-5% recall loss.

Both treat all dimensions equally. They assume a value of 0.1 is as important as 0.9, that the difference between 0.001 and 0.002 matters as much as between 0.5 and 0.501.

**This assumption is wrong.**

## How Human Perception Works

Your eyes don't perceive light linearly. Double the photons doesn't mean double the brightness. The relationship is roughly logarithmic — you're much more sensitive to changes in dark regions than bright ones.

In 1886, Weber and Fechner figured this out. In 2014, Dolby turned it into **PQ (Perceptual Quantizer)**, standardized as SMPTE ST 2084.

The PQ transfer function:

```
L = ((c1 + c2 * Y^m1) / (1 + c3 * Y^m1))^m2
```

Where:
- `Y` is linear luminance (0-10,000 nits)
- `L` is the perceptually encoded value (0-1)
- `c1, c2, c3, m1, m2` are constants from the spec

This curve allocates more bits to dark regions where eyes are sensitive, fewer bits to bright regions where eyes can't tell the difference.

## Applying PQ to Vector Search

Here's the insight: **embedding dimensions aren't all equal either.**

Analyze any embedding model:
- Some dimensions have high variance (carry lots of information)
- Some dimensions cluster near zero (sparse, but important when non-zero)
- Some dimensions have heavy tails (extreme values matter)

Linear quantization treats them all the same. **Perceptual quantization adapts.**

### Hektor's PQ Pipeline

```
┌──────────────┐
│ Raw Vector   │ [0.023, -0.847, 0.001, 0.512, ...]
└──────┬───────┘
       │
       ▼
┌──────────────┐
│ Analyze      │ Compute per-dimension statistics
│ Distribution │ μ, σ, skewness, kurtosis
└──────┬───────┘
       │
       ▼
┌──────────────┐
│ Select Curve │ PQ for sparse dims, linear for uniform
│ Per-Dim      │ HLG for heavy-tailed distributions
└──────┬───────┘
       │
       ▼
┌──────────────┐
│ Apply EOTF   │ Electro-Optical Transfer Function
│              │ Per SMPTE ST 2084 / BT.2100
└──────┬───────┘
       │
       ▼
┌──────────────┐
│ Quantize to  │ Now quantization is perceptually
│ int8/int4    │ uniform, not linearly uniform
└──────────────┘
```

### The Display Profiles

We borrow Hollywood's display standards:

| Profile | Curve | Peak | Use Case |
|---------|-------|------|----------|
| **SDR** | Gamma 2.2 | 100 nits | Basic quantization |
| **HDR10** | PQ ST.2084 | 1000 nits | High dynamic range embeddings |
| **DolbyVision** | PQ + metadata | 4000 nits | Adaptive per-vector curves |
| **HLG** | Hybrid Log-Gamma | 1000 nits | Backwards-compatible |
| **HDR1000** | PQ ST.2084 | 1000 nits | Balanced precision |

### Why Dolby Compatibility Matters

Netflix encodes in Dolby Vision. Disney+ uses HDR10. The entire streaming industry runs on PQ curves.

By using the **same math**, Hektor gains:
- **Battle-tested formulas**: These curves are validated against human perception studies
- **Hardware acceleration**: Modern GPUs have PQ decode in silicon
- **Future-proofing**: As AI moves to video understanding, our quantization is ready

## Real-World Results

We tested on the MTEB benchmark suite (text embeddings) and LAION-5B (image embeddings):

### MTEB (OpenAI text-embedding-3-large)

| Method | Compression | Recall@10 |
|--------|-------------|-----------|
| No compression | 1x | 100% |
| Linear SQ (int8) | 4x | 98.1% |
| Standard PQ | 8x | 96.4% |
| **Hektor PQ (ST.2084)** | 8x | **98.9%** |
| **Hektor PQ (HDR1000)** | 16x | **97.2%** |

### LAION-5B (CLIP ViT-L/14)

| Method | Compression | Recall@10 |
|--------|-------------|-----------|
| No compression | 1x | 100% |
| Linear SQ (int8) | 4x | 97.3% |
| Standard PQ | 8x | 94.8% |
| **Hektor PQ (DolbyVision)** | 8x | **98.1%** |
| **Hektor PQ (HLG)** | 16x | **96.5%** |

The PQ curve consistently outperforms linear quantization at the same compression ratio.

## Implementation Details

### The Core Algorithm

```cpp
// SMPTE ST 2084 (PQ) EOTF
float PQ_EOTF(float E) {
    constexpr float m1 = 0.1593017578125f;
    constexpr float m2 = 78.84375f;
    constexpr float c1 = 0.8359375f;
    constexpr float c2 = 18.8515625f;
    constexpr float c3 = 18.6875f;
    
    float Ep = std::pow(E, 1.0f / m2);
    float num = std::max(Ep - c1, 0.0f);
    float den = c2 - c3 * Ep;
    return std::pow(num / den, 1.0f / m1);
}

// Inverse OETF for encoding
float PQ_OETF(float Y) {
    float Ym1 = std::pow(Y, m1);
    float num = c1 + c2 * Ym1;
    float den = 1.0f + c3 * Ym1;
    return std::pow(num / den, m2);
}
```

### AVX-512 Optimization

We process 16 floats at once:

```cpp
__m512 pq_eotf_avx512(__m512 E) {
    // Vectorized ST 2084 implementation
    __m512 Ep = _mm512_pow_ps(E, _mm512_set1_ps(1.0f / m2));
    __m512 num = _mm512_max_ps(
        _mm512_sub_ps(Ep, _mm512_set1_ps(c1)),
        _mm512_setzero_ps()
    );
    __m512 den = _mm512_sub_ps(
        _mm512_set1_ps(c2),
        _mm512_mul_ps(_mm512_set1_ps(c3), Ep)
    );
    return _mm512_pow_ps(
        _mm512_div_ps(num, den),
        _mm512_set1_ps(1.0f / m1)
    );
}
```

## Using PQ in Hektor

### Python API

```python
from hektor import Index, QuantizationConfig

config = QuantizationConfig(
    method="pq",
    curve="st2084",  # or "hlg", "gamma22", "dolby_vision"
    num_subquantizers=8,
    bits_per_code=8
)

index = Index(dim=1536, quantization=config)
index.add(vectors)
```

### Studio Visual Editor

In Hektor Studio, you can:
1. Load your vectors
2. See the automatic curve selection
3. Override with custom curves
4. Preview quantization error in real-time
5. Export optimized configuration

## The Philosophy

Vector databases are about finding similarity. Similarity is subjective. What matters depends on context.

Perceptual quantization is our acknowledgment that **not all bits are equal**. Some preserve meaning, others preserve noise. Our job is to keep the meaning.

Hollywood figured this out decades ago. We're just applying their wisdom to a new domain.

---

*Perceptual quantization is available in Hektor 4.0+ and Hektor Studio 4.1+.*

```bash
pip install hektor-vdb
```

— *Ali A. Shakil, ARTIFACT VIRTUAL*
